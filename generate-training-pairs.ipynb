{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ee4cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T17:43:12.933669Z",
     "iopub.status.busy": "2024-12-08T17:43:12.933388Z",
     "iopub.status.idle": "2024-12-08T17:43:30.809594Z",
     "shell.execute_reply": "2024-12-08T17:43:30.808916Z"
    },
    "papermill": {
     "duration": 17.881418,
     "end_time": "2024-12-08T17:43:30.811601",
     "exception": false,
     "start_time": "2024-12-08T17:43:12.930183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BlipForConditionalGeneration, BlipProcessor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13da032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T17:43:30.816589Z",
     "iopub.status.busy": "2024-12-08T17:43:30.816126Z",
     "iopub.status.idle": "2024-12-08T17:43:39.841791Z",
     "shell.execute_reply": "2024-12-08T17:43:39.840825Z"
    },
    "papermill": {
     "duration": 9.030037,
     "end_time": "2024-12-08T17:43:39.843712",
     "exception": false,
     "start_time": "2024-12-08T17:43:30.813675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths where the model and processor were saved\n",
    "model_path = '/kaggle/input/blip-trained-on-medical-images/blip/blip_model'\n",
    "processor_path = '/kaggle/input/blip-trained-on-medical-images/blip/blip_processor'\n",
    "\n",
    "# Load the saved model\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Load the saved processor (for preprocessing inputs)\n",
    "blip_processor = BlipProcessor.from_pretrained(processor_path)\n",
    "\n",
    "# Move the model to the desired device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "blip_model = blip_model.to(device)\n",
    "\n",
    "print(\"Model and processor loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5383f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T17:43:39.848620Z",
     "iopub.status.busy": "2024-12-08T17:43:39.848363Z",
     "iopub.status.idle": "2024-12-08T17:43:39.854926Z",
     "shell.execute_reply": "2024-12-08T17:43:39.854213Z"
    },
    "papermill": {
     "duration": 0.010887,
     "end_time": "2024-12-08T17:43:39.856552",
     "exception": false,
     "start_time": "2024-12-08T17:43:39.845665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def prepare_mistral_training_data(\n",
    "    blip_model, \n",
    "    blip_processor, \n",
    "    images_captions,  # Dictionary with image filenames as keys and captions as values\n",
    "    images_path,      # Base path where the images are stored\n",
    "    device\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare training data for Mistral by generating BLIP captions\n",
    "    using images dynamically loaded from disk based on filenames.\n",
    "    \"\"\"\n",
    "    training_pairs = []\n",
    "    blip_model.eval()\n",
    "\n",
    "    for img_file, true_caption in tqdm(images_captions.items()):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(images_path, img_file)\n",
    "        \n",
    "        # Load the image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Generate BLIP caption\n",
    "        inputs = blip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = blip_model.generate(\n",
    "                pixel_values=inputs[\"pixel_values\"], \n",
    "                max_length=128, \n",
    "                num_beams=4, \n",
    "                early_stopping=True\n",
    "            )\n",
    "        blip_caption = blip_processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Create training pair\n",
    "        training_pairs.append({\n",
    "            'blip_caption': blip_caption,\n",
    "            'true_caption': true_caption\n",
    "        })\n",
    "    \n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fc97b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T17:43:39.861037Z",
     "iopub.status.busy": "2024-12-08T17:43:39.860736Z",
     "iopub.status.idle": "2024-12-08T18:14:03.971040Z",
     "shell.execute_reply": "2024-12-08T18:14:03.970121Z"
    },
    "papermill": {
     "duration": 1824.114686,
     "end_time": "2024-12-08T18:14:03.972933",
     "exception": false,
     "start_time": "2024-12-08T17:43:39.858247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image-caption pairs: 7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7326/7326 [30:24<00:00,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the pickle file\n",
    "pickle_path = \"/kaggle/input/chestxray-processed/medical_dataset.pkl\"\n",
    "with open(pickle_path, \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "# Extract data from pickle file\n",
    "images_captions = data['images_captions']\n",
    "reports_with_images = data['reports_with_images']\n",
    "text_of_reports = data['text_of_reports']\n",
    "#Check the structure of the data\n",
    "print(f\"Number of image-caption pairs: {len(images_captions)}\")\n",
    "images_path= '/kaggle/input/chestxray-test/data/images_subset'\n",
    "\n",
    "    \n",
    "# Prepare training data\n",
    "training_pairs = prepare_mistral_training_data(\n",
    "blip_model=blip_model,\n",
    "blip_processor=blip_processor,\n",
    "images_captions=images_captions,\n",
    "images_path=images_path,\n",
    "device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3575225a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T18:14:04.596156Z",
     "iopub.status.busy": "2024-12-08T18:14:04.595807Z",
     "iopub.status.idle": "2024-12-08T18:14:04.606996Z",
     "shell.execute_reply": "2024-12-08T18:14:04.606085Z"
    },
    "papermill": {
     "duration": 0.323534,
     "end_time": "2024-12-08T18:14:04.609235",
     "exception": false,
     "start_time": "2024-12-08T18:14:04.285701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs saved successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"training_pairs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_pairs, f)\n",
    "\n",
    "print(\"Training pairs saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6254305,
     "sourceId": 10133799,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6254566,
     "sourceId": 10134401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6257801,
     "sourceId": 10139338,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1857.410283,
   "end_time": "2024-12-08T18:14:07.914778",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T17:43:10.504495",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
