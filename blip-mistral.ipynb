{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a874884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:55:30.141021Z",
     "iopub.status.busy": "2024-12-08T03:55:30.140311Z",
     "iopub.status.idle": "2024-12-08T03:55:46.946403Z",
     "shell.execute_reply": "2024-12-08T03:55:46.945654Z"
    },
    "papermill": {
     "duration": 16.811252,
     "end_time": "2024-12-08T03:55:46.948426",
     "exception": false,
     "start_time": "2024-12-08T03:55:30.137174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from transformers import (\n",
    "    BlipProcessor, \n",
    "    BlipForConditionalGeneration, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9822ec68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:55:46.953411Z",
     "iopub.status.busy": "2024-12-08T03:55:46.952914Z",
     "iopub.status.idle": "2024-12-08T03:55:46.963805Z",
     "shell.execute_reply": "2024-12-08T03:55:46.963030Z"
    },
    "papermill": {
     "duration": 0.014985,
     "end_time": "2024-12-08T03:55:46.965408",
     "exception": false,
     "start_time": "2024-12-08T03:55:46.950423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_root = \"/kaggle/input/chestxray-test/data\"\n",
    "reports_path = os.path.join(dataset_root, \"reports_subset\", \"ecgen-radiology\")\n",
    "images_path = os.path.join(dataset_root, \"images_subset\")\n",
    "\n",
    "# Function to process dataset\n",
    "def clean_and_process_reports(reports_path, images_path):\n",
    "    # Get the list of XML and PNG files\n",
    "    report_files = sorted([f for f in os.listdir(reports_path) if f.endswith(\".xml\")])\n",
    "    image_files = set([f for f in os.listdir(images_path) if f.endswith(\".png\")])  # Use a set for quick lookup\n",
    "    \n",
    "    # Initialize dictionaries and statistics\n",
    "    clean_images_captions = {}\n",
    "    clean_reports_with_images = {}\n",
    "    clean_text_of_reports = {}\n",
    "    stats = {\n",
    "        'total_reports': len(report_files),\n",
    "        'reports_with_no_image': 0,\n",
    "        'reports_with_empty_sections': 0,\n",
    "        'reports_with_no_impression': 0,\n",
    "        'reports_with_no_findings': 0,\n",
    "        'reports_processed': 0,\n",
    "        'images_processed': 0\n",
    "    }\n",
    "    \n",
    "    print(\"Processing reports...\")\n",
    "    for report_file in tqdm(report_files):\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            report_path = os.path.join(reports_path, report_file)\n",
    "            tree = ET.parse(report_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Find associated images in the report\n",
    "            images_in_report = root.findall(\"parentImage\")\n",
    "            if not images_in_report:\n",
    "                stats['reports_with_no_image'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Extract findings and impression\n",
    "            sections = root.find(\"MedlineCitation\").find(\"Article\").find(\"Abstract\").findall(\"AbstractText\")\n",
    "            findings, impression = None, None\n",
    "            for section in sections:\n",
    "                label = section.get(\"Label\")\n",
    "                if label == \"FINDINGS\":\n",
    "                    findings = section.text\n",
    "                elif label == \"IMPRESSION\":\n",
    "                    impression = section.text\n",
    "            \n",
    "            # Skip reports with no meaningful sections\n",
    "            if not findings and not impression:\n",
    "                stats['reports_with_empty_sections'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Create a caption for the report\n",
    "            caption = (impression or \"\") + \" \" + (findings or \"\")\n",
    "            caption = caption.strip()\n",
    "            if len(caption.split()) < 10:  # Skip short captions\n",
    "                continue\n",
    "            \n",
    "            # Validate and process associated images\n",
    "            valid_images = []\n",
    "            for image in images_in_report:\n",
    "                image_id = f\"{image.get('id')}.png\"\n",
    "                if image_id in image_files:  # Ensure the image exists in the directory\n",
    "                    clean_images_captions[image_id] = caption\n",
    "                    valid_images.append(image_id)\n",
    "                    stats['images_processed'] += 1\n",
    "            \n",
    "            # Add the report if it has valid images\n",
    "            if valid_images:\n",
    "                clean_reports_with_images[report_file] = valid_images\n",
    "                clean_text_of_reports[report_file] = caption\n",
    "                stats['reports_processed'] += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing report {report_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nDataset Cleaning Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key.replace('_', ' ').capitalize()}: {value}\")\n",
    "    \n",
    "    return clean_images_captions, clean_reports_with_images, clean_text_of_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd03aef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:55:46.969552Z",
     "iopub.status.busy": "2024-12-08T03:55:46.969307Z",
     "iopub.status.idle": "2024-12-08T03:55:46.975251Z",
     "shell.execute_reply": "2024-12-08T03:55:46.974601Z"
    },
    "papermill": {
     "duration": 0.009832,
     "end_time": "2024-12-08T03:55:46.976781",
     "exception": false,
     "start_time": "2024-12-08T03:55:46.966949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for Chest X-Ray images and captions\n",
    "    \"\"\"\n",
    "    def __init__(self, images_path, images_captions, processor):\n",
    "        self.images_path = images_path\n",
    "        self.images_captions = images_captions\n",
    "        self.processor = processor\n",
    "        self.image_files = list(images_captions.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = os.path.join(self.images_path, image_file)\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        caption = self.images_captions[image_file]\n",
    "        \n",
    "        # Prepare inputs\n",
    "        inputs = self.processor(\n",
    "            images=image, \n",
    "            text=caption, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.squeeze()\n",
    "            \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1277f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:55:46.980687Z",
     "iopub.status.busy": "2024-12-08T03:55:46.980412Z",
     "iopub.status.idle": "2024-12-08T03:55:59.835046Z",
     "shell.execute_reply": "2024-12-08T03:55:59.833990Z"
    },
    "papermill": {
     "duration": 12.858684,
     "end_time": "2024-12-08T03:55:59.836938",
     "exception": false,
     "start_time": "2024-12-08T03:55:46.978254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3955/3955 [00:12<00:00, 310.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Cleaning Statistics:\n",
      "Total reports: 3955\n",
      "Reports with no image: 104\n",
      "Reports with empty sections: 25\n",
      "Reports with no impression: 0\n",
      "Reports with no findings: 0\n",
      "Reports processed: 3772\n",
      "Images processed: 7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "def main():\n",
    "    reports_path = os.path.join(dataset_root, \"reports_subset\", \"ecgen-radiology\")\n",
    "    images_path = os.path.join(dataset_root, \"images_subset\")\n",
    "    \n",
    "    # Ensure paths exist\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    os.makedirs(reports_path, exist_ok=True)\n",
    "    \n",
    "    # Clean and process reports\n",
    "    clean_images_captions, clean_reports_with_images, clean_text_of_reports = clean_and_process_reports(\n",
    "        reports_path, \n",
    "        images_path\n",
    "    )\n",
    "    \n",
    "    # Save processed dataset (optional)\n",
    "    with open('medical_dataset.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'images_captions': clean_images_captions,\n",
    "            'reports_with_images': clean_reports_with_images,\n",
    "            'text_of_reports': clean_text_of_reports\n",
    "        }, f)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1939,
     "sourceId": 438431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6254305,
     "sourceId": 10133799,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.600327,
   "end_time": "2024-12-08T03:56:02.443430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T03:55:27.843103",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
